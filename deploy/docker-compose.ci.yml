version: "3.9"
services:
  ollama:
    image: nginx:alpine
    container_name: mock-ollama
    volumes:
      - ./mock-ollama.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:11434/api/tags"]
      interval: 5s
      timeout: 3s
      retries: 20
      start_period: 5s

  backend:
    depends_on:
      - ollama
    environment:
      - PRIMARY_MODEL=${PRIMARY_MODEL:-gpt-oss:20b}
