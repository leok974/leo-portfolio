version: "3.9"

# Production-focused compose (immutable image, no source bind mounts).
services:
  ollama:
    image: ollama/ollama:latest
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    volumes:
      - ollama:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 3s
      retries: 5

  ollama-init:
    image: curlimages/curl:8.7.1
    depends_on:
      - ollama
    environment:
      PRIMARY_MODEL: ${PRIMARY_MODEL:-gpt-oss:20b}
    entrypoint: ["/bin/sh", "-lc"]
    command: >-
      set -e;
      echo "[ollama-init] waiting for ollama...";
      until curl -sSf http://ollama:11434/api/tags >/dev/null; do sleep 2; done;
      echo "[ollama-init] pulling ${PRIMARY_MODEL}...";
      curl -sSf -X POST http://ollama:11434/api/pull -H 'Content-Type: application/json' -d "{\"name\":\"${PRIMARY_MODEL}\"}";
      echo "[ollama-init] done."
    restart: "no"

  backend:
    build:
      context: ../assistant_api
      dockerfile: Dockerfile
    env_file:
      - ../assistant_api/.env.prod
    environment:
      - OPENAI_BASE_URL=http://ollama:11434/v1
      - OPENAI_MODEL=gpt-oss:20b
      - PRIMARY_MODEL=${PRIMARY_MODEL:-gpt-oss:20b}
      - FALLBACK_API_KEY_FILE=/run/secrets/openai_api_key
      - OPENAI_API_KEY_FILE=/run/secrets/openai_api_key
    depends_on:
      - ollama
      - ollama-init
    volumes:
      - ../data:/app/data
    expose:
      - "8000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/ready"]
      interval: 30s
      timeout: 5s
      retries: 3
    secrets:
      - openai_api_key

  nginx:
    image: nginx:1.27-alpine
    depends_on:
      - backend
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "80:80"
      - "443:443"
    restart: unless-stopped

volumes:
  ollama:

secrets:
  openai_api_key:
    file: ../secrets/openai_api_key
