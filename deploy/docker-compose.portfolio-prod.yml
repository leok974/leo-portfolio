version: "3.9"

# Portfolio Production Deployment Override
# Deploy to: https://assistant.ledger-mind.org
# Frontend: Portfolio build (dist-portfolio/)
# Backend: FastAPI + Ollama

services:
  backend:
    image: ghcr.io/leok974/leo-portfolio/backend:main
    container_name: portfolio-backend
    environment:
      # Production URLs
      - ALLOWED_ORIGINS=https://assistant.ledger-mind.org
      - BACKEND_URL=https://assistant.ledger-mind.org

      # Database
      - RAG_DB=./data/rag.sqlite
      - RAG_REPOS=leok974/ledger-mind,leok974/leo-portfolio

      # Ollama (primary LLM)
      - OPENAI_BASE_URL=http://ollama:11434/v1
      - OPENAI_MODEL=qwen2.5:7b-instruct-q4_K_M
      - OPENAI_API_KEY_OLLAMA=ollama
      - EMBED_MODEL_QUERY=openai/text-embedding-3-large

      # OpenAI (fallback) - requires FALLBACK_API_KEY from env or secrets
      - FALLBACK_BASE_URL=https://api.openai.com/v1
      - FALLBACK_MODEL=gpt-4o-mini

      # Cloudflare Access (if enabled)
      - CF_ACCESS_TEAM_DOMAIN=${CF_ACCESS_TEAM_DOMAIN:-}
      - CF_ACCESS_AUD=${CF_ACCESS_AUD:-}
      - ACCESS_ALLOWED_EMAILS=${ACCESS_ALLOWED_EMAILS:-}

      # Limits
      - MAX_IMAGE_MB=30
      - MAX_VIDEO_MB=200
    volumes:
      - ../data:/app/data:rw
      - ../assistant_api/.env.prod:/app/.env:ro
    ports:
      - "127.0.0.1:8001:8001"
    depends_on:
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  nginx:
    image: nginx:1.27-alpine
    container_name: portfolio-nginx
    volumes:
      - ./nginx.portfolio.conf:/etc/nginx/conf.d/default.conf:ro
      - ../dist-portfolio:/usr/share/nginx/html:ro
    ports:
      - "80:80"
      # Uncomment for HTTPS termination at nginx (if not using Cloudflare Tunnel)
      # - "443:443"
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1/healthz || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
    # Uncomment for TLS certificates
    # volumes (additional):
    #   - ./certs:/etc/nginx/certs:ro

  ollama:
    image: ollama/ollama:latest
    container_name: portfolio-ollama
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "127.0.0.1:11434:11434"
    restart: unless-stopped
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

volumes:
  ollama-data:
    driver: local
