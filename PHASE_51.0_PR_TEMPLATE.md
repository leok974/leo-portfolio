## Phase 51.0 â€” Analytics Loop / RAG Insights

**Type**: Feature
**Status**: âœ… Ready for Review
**Branch**: `rag-and-telemetry`

---

### ðŸŽ¯ Overview

Implements a complete **Analytics Loop** that combines nightly data collection, RAG-based insights, and AI-powered recommendations to provide actionable intelligence about application health.

**Key Components**:
- ðŸ”„ Automated ETL pipeline (Reports â†’ KPIs â†’ Trends â†’ Insights)
- ðŸ§  RAG integration (local embeddings + SQLite vector store)
- ðŸ¤– AI insights (Ollama with qwen2.5:7b)
- ðŸ“Š Anomaly detection (z-score analysis, Â±2Ïƒ threshold)
- ðŸ“ Auto-generated Markdown reports
- ðŸ”Œ FastAPI endpoints (`/analytics/latest`, `/analytics/health`)
- âš™ï¸ GitHub Actions (nightly workflow + PR comments)

---

### ðŸ“¦ What's New

#### Core Implementation
- âœ¨ **Analytics Pipeline** (`analytics/pipeline.py`)
  - Orchestrates data collection, analysis, and reporting
  - CLI: `python -m analytics.pipeline --window-days 7`
  - Developer-friendly output with emojis and progress indicators

- âœ¨ **Data Collectors** (`analytics/collectors/`)
  - `nightly_loader.py`: Merges JSON reports from SEO/Playwright/Prometheus
  - `kpi_extractor.py`: Extracts 4 core KPIs (SEO %, PW %, P95, autofix Î”)
  - `trend_detector.py`: Z-score anomaly detection over sliding window

- âœ¨ **RAG Components** (`analytics/rag/`)
  - `embedder_local.py`: Local embeddings via `intfloat/e5-base-v2`
  - `query_engine.py`: SQLite vector store with cosine similarity search
  - Context-aware insights from last 7 days of data

- âœ¨ **Summarizers** (`analytics/summarizers/`)
  - `insight_llm.py`: AI-generated recommendations using Ollama
  - `report_builder.py`: Markdown report formatting with KPIs, trends, insights

#### API Integration
- âœ¨ **FastAPI Router** (`assistant_api/routers/analytics_insights.py`)
  - `GET /analytics/latest`: Latest insight report (Markdown + JSON trend)
  - `GET /analytics/health`: System health check
  - Protected by existing `ANALYTICS_ENABLED` flag (defaults to enabled)

#### Automation
- âœ¨ **Nightly Workflow** (`.github/workflows/analytics-nightly.yml`)
  - Runs at 02:30 UTC daily
  - Uploads artifacts: `analytics-outputs` (30d), `nightly-data` (90d)

- âœ¨ **PR Comment Workflow** (`.github/workflows/analytics-pr-comment.yml`)
  - Posts sticky PR comments with latest insights
  - Falls back to informative message if no report available

#### Developer Tools
- âœ¨ **PowerShell Script** (`scripts/analytics.ps1`)
  - Local pipeline runner with colored output
  - Usage: `.\scripts\analytics.ps1 -WindowDays 7`

- âœ¨ **Makefile Target**
  - `make analytics`: One-command pipeline execution

#### Documentation
- ðŸ“š **Complete Guide** (`PHASE_51.0_COMPLETE.md`)
- ðŸš€ **Quick Start** (`PHASE_51.0_QUICKSTART.md`)
- ðŸ“Š **Summary** (`PHASE_51.0_SUMMARY.md`)
- ðŸ“– **API Docs** (`docs/API.md` - analytics section)
- ðŸ“ **Changelog** (`CHANGELOG.md` - Phase 51.0 entry)

#### Sample Data
- ðŸ“„ **Seed Reports** (`reports/{seo,playwright,prometheus}/sample-2025-10-09.json`)
  - Enables first-run testing without waiting for nightly workflow

---

### ðŸ”§ Technical Details

**Dependencies** (already in `requirements.txt`):
- `sentence-transformers==5.1.1` (embeddings)
- `faiss-cpu==1.12.0` (vector similarity)
- `numpy==2.3.3`, `pandas==2.2.2`, `scikit-learn==1.7.2`
- `openai>=1.40.0` (Ollama client)

**Environment Variables** (all optional):
```bash
ANALYTICS_ENABLED=true              # Enable endpoints (default: true)
OPENAI_BASE_URL=http://...          # Ollama endpoint (default: localhost:11434)
OPENAI_MODEL=qwen2.5:7b-instruct... # Model name
```

**Artifacts Generated** (git-ignored):
```
analytics/
â”œâ”€â”€ rag/vector_store.sqlite
â”œâ”€â”€ outputs/insight-summary.md
â””â”€â”€ outputs/trend-report.json

data/nightly/*.json
```

**Idempotency**:
- âœ… Safe to re-run pipeline on same date (updates in-place)
- âœ… RAG index is additive (can re-index without data loss)
- âœ… API endpoints return cached reports (no side effects)

---

### ðŸ§ª Testing

#### Manual Testing
```bash
# 1. Install dependencies
pip install -r assistant_api/requirements.txt

# 2. Start Ollama (if not running)
ollama serve

# 3. Run pipeline locally
make analytics

# 4. View reports
code analytics/outputs/insight-summary.md
cat analytics/outputs/trend-report.json | jq .

# 5. Test API endpoints
curl http://localhost:8010/analytics/latest | jq .status
curl http://localhost:8010/analytics/health | jq .
```

#### Expected Behavior
- âœ… Pipeline completes in <30 seconds (first run may take longer for model download)
- âœ… `insight-summary.md` contains KPIs, trends, and AI insight
- âœ… `trend-report.json` has valid JSON with series and anomalies
- âœ… API returns `status: "ok"` when reports exist
- âœ… API returns `status: "pending"` when reports not yet generated

#### Edge Cases Handled
- ðŸ›¡ï¸ No nightly data â†’ Uses sample data from `reports/`
- ðŸ›¡ï¸ Ollama unavailable â†’ Generates fallback insight with error message
- ðŸ›¡ï¸ < 3 data points â†’ Trend detection skips anomaly flagging
- ðŸ›¡ï¸ RAG index fails â†’ Pipeline continues without context retrieval

---

### ðŸ“Š Files Changed

#### Added (30 files)
```
analytics/
  __init__.py
  pipeline.py                              (170 lines)
  collectors/
    __init__.py
    nightly_loader.py                      (100 lines)
    kpi_extractor.py                       (90 lines)
    trend_detector.py                      (120 lines)
  rag/
    __init__.py
    embedder_local.py                      (45 lines)
    query_engine.py                        (180 lines)
  summarizers/
    __init__.py
    insight_llm.py                         (110 lines)
    report_builder.py                      (95 lines)
  outputs/.gitkeep

assistant_api/routers/analytics_insights.py  (100 lines)

.github/workflows/
  analytics-nightly.yml                    (60 lines)
  analytics-pr-comment.yml                 (55 lines)

scripts/analytics.ps1                      (45 lines)

reports/
  seo/sample-2025-10-09.json
  playwright/sample-2025-10-09.json
  prometheus/sample-2025-10-09.json

data/nightly/.gitkeep

docs/
  PHASE_51.0_COMPLETE.md                   (650 lines - comprehensive guide)
  PHASE_51.0_QUICKSTART.md                 (200 lines - 5-min setup)
  PHASE_51.0_SUMMARY.md                    (450 lines - implementation summary)
```

#### Modified (4 files)
```
assistant_api/main.py                      (+7 lines - router registration)
.gitignore                                 (+6 lines - analytics patterns)
Makefile                                   (+7 lines - analytics target)
CHANGELOG.md                               (+25 lines - Phase 51.0 entry)
docs/API.md                                (+85 lines - analytics endpoints)
```

**Total**: ~2,500+ lines of production code + documentation

---

### ðŸŽ¬ Demo

**Run Pipeline**:
```bash
$ make analytics

ðŸš€ Phase 51.0 â€” Analytics Pipeline Starting...
ðŸ“… Processing date: 2025-10-09
ðŸ“¦ Loading nightly reports...
   âœ“ Loaded 3 source files
ðŸ“Š Extracting KPIs...
   âœ“ Extracted 4 KPIs
      - seo_coverage_pct: 91.67
      - playwright_pass_pct: 95.56
      - avg_p95_ms: 687.43
      - autofix_delta_count: 0
ðŸ“ˆ Detecting trends (window: 7 days)...
   âœ“ Analyzed 1 data points
   âœ“ No anomalies detected
ðŸ§  Initializing RAG embeddings...
   âœ“ RAG index updated
ðŸ’¡ Generating AI insight...
   âœ“ Insight generated
ðŸ“ Writing reports...
   âœ“ Wrote analytics/outputs/insight-summary.md
   âœ“ Wrote analytics/outputs/trend-report.json
âœ… Analytics pipeline completed successfully!
```

**Sample Insight** (excerpt):
```markdown
# Nightly Analytics â€” 2025-10-09

## ðŸ“Š KPIs
- **SEO Coverage %**: `91.67`
- **Playwright Pass Rate %**: `95.56`
- **Avg P95 Latency (ms)**: `687.4`
- **Autofix Changes**: `0`

## ðŸ“ˆ Trends
âœ… No significant anomalies detected (all metrics within 2Ïƒ).

## ðŸ§  AI Insight
Current metrics indicate healthy system stability. SEO coverage
remains above the 90% target...

**Next Actions:**
- Fix title length on /public/metrics.html
- Investigate popover timeout
- Profile /api/seo/tune for optimization
```

---

### âœ… Checklist

#### Pre-Merge
- [x] All files created and tested locally
- [x] Pipeline runs end-to-end successfully
- [x] Sample data produces valid reports
- [x] API endpoints return expected responses
- [x] PowerShell script works on Windows
- [x] Makefile target works
- [x] Documentation is comprehensive
- [x] .gitignore excludes generated artifacts
- [x] Changelog updated
- [x] API docs updated

#### Post-Merge
- [ ] Verify nightly workflow runs successfully
- [ ] Check PR comment workflow on first PR
- [ ] Configure GitHub Actions secrets (if using remote Ollama)
- [ ] Monitor first week of trend data accumulation
- [ ] Review first AI-generated insights for quality
- [ ] Add unit tests for collectors
- [ ] Add E2E tests for API endpoints

---

### ðŸš€ Deployment Notes

**Production Setup**:
1. Install Ollama on server: `curl -fsSL https://ollama.com/install.sh | sh`
2. Pull model: `ollama pull qwen2.5:7b-instruct-q4_K_M`
3. Start service: `ollama serve` (or systemd unit)
4. Merge this PR
5. Nightly workflow runs automatically at 02:30 UTC

**Optional GitHub Secrets**:
- `OPENAI_BASE_URL`: Remote Ollama endpoint (if not local)
- `OPENAI_API_KEY`: API key (if using OpenAI instead of Ollama)

---

### ðŸ“š Further Reading

- **Architecture**: See `PHASE_51.0_COMPLETE.md` Â§ Architecture
- **RAG Deep Dive**: See `PHASE_51.0_COMPLETE.md` Â§ RAG Components
- **API Reference**: See `docs/API.md` Â§ Analytics Insights
- **Troubleshooting**: See `PHASE_51.0_QUICKSTART.md` Â§ Troubleshooting

---

### ðŸ”— Related Issues

- Closes #XXX (Analytics Loop feature request)
- Related to Phase 50.9 (SEO Intelligence)
- Builds on Phase 50.8 (Behavior Metrics)

---

**Ready for review!** ðŸŽ‰

cc @reviewers Please focus on:
- [ ] Pipeline orchestration logic (`analytics/pipeline.py`)
- [ ] FastAPI endpoint security (guard by flag)
- [ ] GitHub Actions workflow syntax
- [ ] Documentation clarity

---

*Generated with Phase 51.0 Analytics Loop / RAG Insights*
